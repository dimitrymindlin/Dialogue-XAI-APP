xai_explanations:
  - explanation_name: "ModelPredictionConfidence"
    description: "This explanation provides information about the model's confidence in its prediction."
    explanation_steps:
      - step_name: "Concept"
        description: >
          The model prediction confidence explanation shows how certain the model is in its decision, influenced by dataset features. Confidence can be high or low.
      - step_name: "Confidence"
        description: >
          {{model_confidence.confidence_description}}

  - explanation_name: "FeatureImportances"
    description: "Understanding the importance and influence of features in the model's decision-making."
    explanation_steps:
      - step_name: "Concept"
        description: >
          Feature importance explanations show how individual features influence predictions, either toward over or under 50k, with varying strength. This helps identify key drivers behind the model’s decisions.
          After listing the features, ask if the user would like to see a plot visualizing the feature importance and influence on the model’s decision.
      - step_name: "FeatureInfluencesPlot"
        description: >
          Reading plots requires some knowledge of data science or statistics, consider not using it for lay users unless specifically asked about or very suitable.
          A plot visualizing feature importance and influence on the model’s decision. Blue bars indicate features in favor of 'under 50k', red bars toward 'over 50k'. The plot lacks explanations, so provide context if needed. Include the placeholder ##FeatureInfluencesPlot## to give this explanation fluently in the text and it will be substituted by the chart.
          The base value of this SHAP explanation is 0.75 in favor of class 'under 50k' which can be important to mention.
      - step_name: "FeaturesInFavourOfOver50k"
        description: >
          The base value of this SHAP explanation is 0.75 in favor of class 'under 50k'.
          {{feature_importance.features_in_favour_of_over_50k}}
      - step_name: "FeaturesInFavourOfUnder50k"
        description: >
          The base value of this SHAP explanation is 0.75 in favor of class 'under 50k'.
          {{feature_importance.features_in_favour_of_under_50k}}
      - step_name: "WhyThisFeatureImportant"
        description: >
          Check PossibleClarifications for a reply to this question. We cannot address why a feature is specially important
          beyond explaining how features influence the model's decision and how the importances are learned during training and observing many examples.

  - explanation_name: "Counterfactuals"
    description: "Answers questions about how to change the instance to get a different prediction."
    explanation_steps:
      - step_name: "Concept"
        description: >
          Counterfactual explanations highlight feature changes that alter a model’s prediction. The method prioritizes minimal counterfactuals, modifying only one attribute.
      - step_name: "ImpactMultipleFeatures"
        description: >
          {{counterfactuals.possible_counterfactuals}}
      - step_name: "ImpactSingleFeature"
        description: >
          Understanding individual feature impact on model predictions. If no single-feature counterfactuals are found, check the CeterisParibus explanation. {{counterfactuals.single_feature_cf}}

  - explanation_name: "AnchorExplanation"
    description: "Finding the minimal set of features that define or anchor the prediction."
    explanation_steps:
      - step_name: "Concept"
        description: >
          Anchor explanations identify the minimal set of features that anchor the model’s decision. They provide a clear, human-understandable explanation for the model’s prediction that is similar to the most important features.
      - step_name: "Anchor"
        description: >
          Anchor showing which features with their current values need to be present for the model to predict the current model prediction. {{anchor.anchor_text}}

  - explanation_name: "FeatureStatistics"
    description: "An overview of the statistical distribution of features used in the model, such as minimum and maximum
    values of features, the mean and occurrences of categories."
    explanation_steps:
      - step_name: "Concept"
        description: >
          A statistical breakdown of features (ranges, means, distributions) helps understand the dataset, revealing imbalances, value ranges, and categorical options.
      - step_name: "Feature Statistics"
        description: >
          {{feature_statistics.feature_statistics}}

  - explanation_name: "TextualPartialDependence"
    description: "Understanding the global relationship between a feature and the model's prediction."
    explanation_steps:
      - step_name: "Concept"
        description: >
          Textual PDP explanations describe how a feature affects the model’s prediction while keeping others constant. They highlight global relationships and how predictions change at specific feature values.
      - step_name: "PDPDescription"
        description: >
          {{pdp.all_pdp_text}}

  - explanation_name: "PossibleClarifications"
    description: "Here are some clarification with common user questions."
    explanation_steps:
      - step_name: "Concept"
        description: >
          Possible clarifications provide answers to common user questions and help in understanding the explanations better.
      - step_name: "ClarificationsList"
        description: >
          {{static_clarifications.all_clarifications}}

  - explanation_name: "CeterisParibus"
    description: "Understanding the model's decision-making by observing how the model's prediction changes when only one
    feature is changed."
    explanation_steps:
      - step_name: "Concept"
        description: >
          Ceteris Paribus explanations show how changing one feature affects the model’s prediction while keeping others constant, revealing individual feature impact.
      - step_name: "PossibleClassFlips"
        description: >
          {{ceteris_paribus.possible_class_flips}}
      - step_name: "ImpossibleClassFlips"
        description: >
          {{ceteris_paribus.impossible_class_flips}}

  - explanation_name: "ScaffoldingStrategy"
    description: "A strategy for improving understanding by simplifying, repeating, and eliciting feedback."
    explanation_steps:
      - step_name: "Reformulating"
        description: >
          Reformulating the explanation in a simpler way.

      - step_name: "Repeating"
        description: >
          Repeating the explanation slightly differently to reinforce understanding.

      - step_name: "ElicitingFeedback"
        description: >
          A question prompting the user to summarize or restate key parts of the explanation in their own words. It assesses understanding and identifies areas needing clarification based on conversation history and context.